{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import imgkit\n",
    "import pandas as pd\n",
    "import requests"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DEBUG = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## IMPORT DATASET\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Grocery_and_Gourmet_Food\", streaming=True, trust_remote_code=True)\n",
    "print(type(dataset))\n",
    "splits = dataset.keys()\n",
    "#print all splits\n",
    "print(splits)\n",
    "\n",
    "for example in dataset[\"full\"]:\n",
    "    print(example)\n",
    "    break  # Remove this line to process the entire dataset\n",
    "\n",
    "dataset_iterator = iter(dataset[\"full\"])\n",
    "#get example[title]\n",
    "print(next(dataset_iterator)[\"title\"])\n",
    "#get length of dataset\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import shutil\n",
    "pwd = os.path.dirname(os.getcwd())\n",
    "print(pwd)\n",
    "font_path = os.path.join(pwd, 'DejaVuSans.ttf')\n",
    "dataset_path = os.path.join(pwd, \"data\" ,\"dataset\", \"webpages\")\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "else:\n",
    "    print(\"Folder already exists, deleting and creating new one\")\n",
    "    shutil.rmtree(dataset_path)\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function to create custom html file"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "def create_html_with_roboto(file_name, title, body, ):\n",
    "    \"\"\"\n",
    "    Create an HTML file with the given title and body, using the Roboto font.\n",
    "\n",
    "    Parameters:\n",
    "        title (str): The title of the HTML document.\n",
    "        body (str): The body content of the HTML document.\n",
    "        file_name (str): The name of the file to save the content to.\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>{title}</title>\n",
    "        <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: 'Roboto', sans-serif;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>{title}</h1>\n",
    "        <p>{body}</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    save_html_to_file(html_content, file_name)\n",
    "\n",
    "def create_html_with_font(path_file\n",
    "                          ,title, body,font_path= os.path.join(os.getcwd(), \"DejaVuSans.ttf\")):\n",
    "    \"\"\"\n",
    "    Create an HTML file with the given title and body, using a specified font.\n",
    "\n",
    "    Parameters:\n",
    "        title (str): The title of the HTML document.\n",
    "        body (str): The body content of the HTML document.\n",
    "        file_name (str): The name of the file to save the content to.\n",
    "    \"\"\"\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>{title}</title>\n",
    "        <style>\n",
    "            @font-face {{\n",
    "                font-family: 'DejaVuSans';\n",
    "                src: url('{font_path}');\n",
    "            }}\n",
    "            body {{\n",
    "                font-family: 'DejaVuSans', sans-serif;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>{title}</h1>\n",
    "        <p>{body}</p>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    save_html_to_file(html_content, path_file)\n",
    "\n",
    "def save_html_to_file(html_content, path_file):\n",
    "    \"\"\"\n",
    "    Save the modified HTML content to a file.\n",
    "\n",
    "    Parameters:\n",
    "        html_content (str): The HTML content as a string.\n",
    "        file_name (str): The name of the file to save the content to.\n",
    "    \"\"\"\n",
    "    with open(path_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "    return path_file\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#test\n",
    "if DEBUG:\n",
    "    create_html_with_font(\"Sample Title\", \"This is the body content.\", os.path.join(dataset_path, \"output.html\"))\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "import random\n",
    "import math\n",
    "\n",
    "def select_target_word(text):\n",
    "    words = re.split(r'\\W+', text)  # Split by any non-word characters\n",
    "    words = [word for word in words if word.isalpha()]  # Keep only words with alphabetic characters\n",
    "    \n",
    "    if not words:\n",
    "        raise ValueError(\"No valid candidate words found.\")\n",
    "    \n",
    "    valid_words = [word for word in words if len(word) >= 2]  # Filter words by minimum length of 2 characters\n",
    "    \n",
    "    if not valid_words:\n",
    "        raise ValueError(\"No valid candidate words found with the required length.\")\n",
    "    \n",
    "    target_word = random.choice(valid_words)\n",
    "    return target_word"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Width Characters injection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ZeroWidthSPaceAttack:\n",
    "    '''define list of malicious characters'''\n",
    "    def __init__(self):\n",
    "        #define the list of malicious symbols\n",
    "        self.symbols = [u'\\u200b', u'\\u200c', u'\\u200d', u'\\u200e', u'\\u200f', #U+200x\n",
    "                      u'\\u202a', u'\\u202b', u'\\u202c', u'\\u202d', #U+202x\n",
    "                      u'\\u2060', u'\\u2061', u'\\u2062', u'\\u2063', u'\\u2064',\n",
    "                    #   u'\\u2065', u'\\u2066', u'\\u2067', u'\\u2068', u'\\u2069', NOT SUPPORTED BY FONT\n",
    "                      u'\\u206a', u'\\u206b', u'\\u206c', u'\\u206d', u'\\u206e' #U+206x\n",
    "                      ]\n",
    "        self.num_malicius_chars = len(self.symbols)\n",
    "\n",
    "    '''insertion of malicious input in the middle of a given word;\n",
    "        for example, given the word \"love\", the result is \"loXve\".\n",
    "    '''\n",
    "    def mask1(self, word, index = 0, random = True):\n",
    "        '''word = target word \\n index = index of malicious symbols from the\n",
    "        given list\\nrandom = if random True, a randomic index is selected\\n'''\n",
    "\n",
    "        #check the index\n",
    "        if index < 0 or index > len(self.symbols):\n",
    "            raise Exception(\"Invalid index.\")\n",
    "\n",
    "        #sample the index, if required\n",
    "        if random:\n",
    "            index = np.random.randint(len(self.symbols))\n",
    "\n",
    "        #get the target character\n",
    "        code = self.symbols[index]\n",
    "\n",
    "        #prepare the result. it must to be unicode\n",
    "        poison = []\n",
    "\n",
    "        #calculate the middle of the word\n",
    "        mid = len(word) // 2\n",
    "\n",
    "        #create the final message\n",
    "        poison.append(word[:mid])\n",
    "        poison.append(code)\n",
    "        poison.append(word[mid:])\n",
    "\n",
    "        poison = ''.join(poison)\n",
    "\n",
    "        return poison\n",
    "\n",
    "    '''insertion of malicious input between each character of the word;\n",
    "\n",
    "        for example, given the word \"love\", the result is \"lXoXvXe\".\n",
    "    '''\n",
    "    def mask2(self, word, index = 0, random = True):\n",
    "        '''word = target word\\nindex = index of malicious symbols from the\n",
    "        given list\\nrandom = if random True, a randomic index is selected\\n'''\n",
    "\n",
    "        #check the index\n",
    "        if index < 0 or index > len(self.symbols):\n",
    "            raise Exception(\"Invalid index.\")\n",
    "\n",
    "        #sample the index, if required\n",
    "        if random:\n",
    "            index = np.random.randint(len(self.symbols))\n",
    "\n",
    "        #get the target character\n",
    "        code = self.symbols[index]\n",
    "\n",
    "        #prepare the result. it must to be unicode\n",
    "        poison = []\n",
    "\n",
    "        #calculate the middle of the word\n",
    "        mid = len(word) // 2\n",
    "\n",
    "        #create the final message\n",
    "        poison.append(word[:mid])\n",
    "        # For now 3, in the midde\n",
    "        poison.append(code)\n",
    "        poison.append(code)\n",
    "        poison.append(code)\n",
    "        \n",
    "        poison.append(word[mid:])\n",
    "\n",
    "        return ''.join(poison)\n",
    "\n",
    "    ''' define a function that remove Zero-Width SPace (ZWSP) characters '''\n",
    "    def sanitization(self, sentence):\n",
    "        #blacklist characters removal\n",
    "        res = ''.join([c for c in sentence if c not in self.symbols])\n",
    "\n",
    "        return res"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def replace_word_in_html(html_content, tag_list, target_word, mask, output_path):\n",
    "    \n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    for tag in tag_list:\n",
    "        elements= soup.find_all(tag)\n",
    "        for elem in elements:\n",
    "            for text_element in elem.find_all(string=True, recursive=True):\n",
    "                # Only replace the target_word in text nodes\n",
    "                if target_word in text_element:\n",
    "                    # Replace target_word with new_word\n",
    "                    new_text = text_element.replace(target_word, mask)\n",
    "                    text_element.replace_with(new_text)  # Update the text node with the new text\n",
    "  \n",
    "    \n",
    "    # Save file\n",
    "    save_html_to_file(str(soup), output_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "''' define a function that remove Zero-Width SPace (ZWSP) characters '''\n",
    "def create_zew_mask1_html(output_path_attak_method, title, body, id):\n",
    "    path= output_path_attak_method\n",
    "    zew=ZeroWidthSPaceAttack()\n",
    "    symbols_len=zew.num_malicius_chars\n",
    "    \n",
    "    #set the target word random form body\n",
    "    target_word=select_target_word(body)\n",
    "    #select random index\n",
    "    i_symbol = np.random.randint(symbols_len)\n",
    "\n",
    "    poisoned_title = title.replace(target_word,zew.mask1(target_word,i_symbol,random=False))\n",
    "    poisoned_body = body.replace(target_word,zew.mask1(target_word,i_symbol,random=False))\n",
    "    symbol_string=f\"u{ord(zew.symbols[i_symbol]):04X}\"\n",
    "    path_html = os.path.join(path, f\"{id}_{symbol_string}_{target_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, poisoned_title, poisoned_body,font_path)\n",
    "    return path_html\n",
    "\n",
    "def create_zew_mask2_html(output_path_attak_method, title, body, id):\n",
    "    path= output_path_attak_method\n",
    "    zew=ZeroWidthSPaceAttack()\n",
    "    symbols_len=zew.num_malicius_chars\n",
    "    \n",
    "    #set the target word random form body\n",
    "    target_word=select_target_word(body)\n",
    "    #select random index\n",
    "    i_symbol = np.random.randint(symbols_len)\n",
    "\n",
    "    poisoned_title = title.replace(target_word,zew.mask2(target_word,i_symbol,random=False))\n",
    "    poisoned_body = body.replace(target_word,zew.mask2(target_word,i_symbol,random=False))\n",
    "    symbol_string=f\"u{ord(zew.symbols[i_symbol]):04X}\"\n",
    "    path_html = os.path.join(path, f\"{id}_{symbol_string}_{target_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, poisoned_title, poisoned_body,font_path)\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#test funtions\n",
    "if DEBUG:\n",
    "    title = \"i love drugs\"\n",
    "    body = \"i love drugs\"\n",
    "\n",
    "    dataset_obf= os.path.join(dataset_path, \"Data obfuscation\")\n",
    "    dataset_mask1 = os.path.join(dataset_obf, \"Zero-Width_Mask1\")\n",
    "    dataset_mask2 = os.path.join(dataset_obf, \"Zero-Width_Mask2\")\n",
    "    if not os.path.exists(dataset_mask1):\n",
    "        os.makedirs(dataset_mask1)\n",
    "    if not os.path.exists(dataset_mask2):\n",
    "        os.makedirs(dataset_mask2)\n",
    "    print(create_zew_mask1_html(dataset_mask1, title, body, 1))\n",
    "    print(create_zew_mask2_html(dataset_mask2, title, body, 1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homoglyph Substitution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "confusables = dict()\n",
    "intentionals = dict()\n",
    "\n",
    "# Retrieve Unicode Confusable homoglyph characters\n",
    "conf_resp = requests.get(\"https://www.unicode.org/Public/security/latest/confusables.txt\", stream=True)\n",
    "for line in conf_resp.iter_lines():\n",
    "  if len(line):\n",
    "    line = line.decode('utf-8-sig')\n",
    "    if line[0] != '#':\n",
    "      line = line.replace(\"#*\", \"#\")\n",
    "      _, line = line.split(\"#\", maxsplit=1)\n",
    "      if line[3] not in confusables:\n",
    "        confusables[line[3]] = []\n",
    "      confusables[line[3]].append(line[7])\n",
    "\n",
    "# Retrieve Unicode Intentional homoglyph characters\n",
    "int_resp = requests.get(\"https://www.unicode.org/Public/security/latest/intentional.txt\", stream=True)\n",
    "\n",
    "for line in int_resp.iter_lines():\n",
    "  if len(line):\n",
    "    line = line.decode('utf-8-sig')\n",
    "    if line[0] != '#':\n",
    "      line = line.replace(\"#*\", \"#\")\n",
    "      _, line = line.split(\"#\", maxsplit=1)\n",
    "      if line[3] not in intentionals:\n",
    "        intentionals[line[3]] = []\n",
    "      intentionals[line[3]].append(line[7])\n",
    "\n",
    "def replace_text_with_homoglyphs(text, homoglyphs):\n",
    "  output=\"\"\n",
    "  for i in text:\n",
    "      if i in homoglyphs:\n",
    "          output += random.choice(homoglyphs[i])\n",
    "      else:\n",
    "          output += i\n",
    "\n",
    "  return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def create_homoglyph_html(output_path_attak_method, title, body, id):\n",
    "    path= output_path_attak_method\n",
    "    #set the target word random form body\n",
    "    target_word=select_target_word(body)\n",
    "    obfuscated_word=replace_text_with_homoglyphs(target_word,intentionals)\n",
    "    while(obfuscated_word==target_word):\n",
    "       print(\"Homoglyphs, same obfuscated word generated\")\n",
    "       target_word=select_target_word(body)\n",
    "       obfuscated_word=replace_text_with_homoglyphs(target_word,intentionals)\n",
    "\n",
    "    # Replace the target word with a homoglyph\n",
    "    poisoned_title=title.replace(target_word,obfuscated_word)\n",
    "    poisoned_body=body.replace(target_word,obfuscated_word)\n",
    "    path_html = os.path.join(path, f\"{id}_{target_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, poisoned_title, poisoned_body,font_path)\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    homoglyph_path = os.path.join(dataset_obf, \"Homoglyph\")\n",
    "    if not os.path.exists(homoglyph_path):\n",
    "        os.makedirs(homoglyph_path)\n",
    "    create_homoglyph_html(homoglyph_path, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Font poisoning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def map_letters_in_file(input_file_path, letter_mapping, output_file_path=None):\n",
    "    \"\"\"\n",
    "    Replace letters in HTML text according to a custom mapping.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Path to input HTML file\n",
    "        letter_mapping (dict): Dictionary mapping letters to their replacements\n",
    "        output_file_path (str, optional): Path for output file\n",
    "    \"\"\"\n",
    "    # Set default output path if none provided\n",
    "    if output_file_path is None:\n",
    "        base, ext = os.path.splitext(input_file_path)\n",
    "        output_file_path = f\"{base}_mapped{ext}\"\n",
    "    \n",
    "    # Read input file\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "    \n",
    "    def map_letter(char):\n",
    "        # Only map if character exists in mapping\n",
    "        return letter_mapping.get(char, char)\n",
    "    \n",
    "    # Process all text nodes while preserving HTML structure\n",
    "    def process_node(element):\n",
    "        for child in element.children:\n",
    "            if isinstance(child, str):\n",
    "                new_text = ''.join(map_letter(c) for c in child)\n",
    "                child.replace_with(new_text)\n",
    "            else:\n",
    "                process_node(child)\n",
    "    \n",
    "    # Process all content in body\n",
    "    if soup.body:\n",
    "        process_node(soup.body)\n",
    "    \n",
    "    # Save the modified HTML\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(str(soup.prettify()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def modify_font(html_file, font_file,output_path):\n",
    "    \"\"\"\n",
    "    Modifies the font in the given HTML file to use a custom font.\n",
    "\n",
    "    Parameters:\n",
    "        html_file (str): Path to the HTML file to modify.\n",
    "        font_file (str): Path to the local font file to use (e.g., 'custom-font.ttf').\n",
    "    \n",
    "    Returns:\n",
    "        str: Modified HTML as a string.\n",
    "    \"\"\"\n",
    "    # Load the HTML file\n",
    "    with open(html_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, \"html.parser\")\n",
    "    \n",
    "    # Remove existing font-family declarations in <style> blocks\n",
    "    for style_tag in soup.find_all(\"style\"):\n",
    "        # Use regex to remove font-family definitions\n",
    "        style_tag.string = re.sub(r\"@font-face\\s*{[^}]*}\", \"\", style_tag.string, flags=re.DOTALL)\n",
    "        style_tag.string = re.sub(r\"font-family:[^;]*;\", \"\", style_tag.string if style_tag.string else \"\")\n",
    "\n",
    "    # Remove inline font-family declarations\n",
    "    for tag in soup.find_all(style=True):\n",
    "        # Split the style attribute and filter out font-family\n",
    "        styles = tag[\"style\"].split(\";\")\n",
    "        filtered_styles = [s for s in styles if not s.strip().startswith(\"font-family\")]\n",
    "        tag[\"style\"] = \";\".join(filtered_styles)\n",
    "\n",
    "    # Add the new custom font definition in a new <style> tag\n",
    "    custom_style = f\"\"\"\n",
    "    @font-face {{\n",
    "        font-family: 'CustomFont';\n",
    "        src: url('{font_file}') format('truetype');\n",
    "    }}\n",
    "    body, h1, h2, h3, p, ul, li {{\n",
    "        font-family: 'CustomFont', sans-serif !important;\n",
    "    }}\n",
    "    \"\"\"\n",
    "    new_style_tag = soup.new_tag(\"style\")\n",
    "    new_style_tag.string = custom_style\n",
    "\n",
    "    # Insert the new style tag into the <head>\n",
    "    if soup.head:\n",
    "        soup.head.append(new_style_tag)\n",
    "    else:\n",
    "        head_tag = soup.new_tag(\"head\")\n",
    "        head_tag.append(new_style_tag)\n",
    "        soup.insert(0, head_tag)\n",
    "    save_html_to_file(str(soup), output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## Font map used to correctly map glyphs to corresponding c\n",
    "font_map = {\n",
    "    \"a\": \"z\",\n",
    "    \"b\": \"a\", \n",
    "    \"c\": \"b\",\n",
    "    \"d\": \"c\",\n",
    "    \"e\": \"d\",\n",
    "    \"f\": \"e\",\n",
    "    \"g\": \"f\",\n",
    "    \"h\": \"g\",\n",
    "    \"i\": \"h\",\n",
    "    \"j\": \"i\",\n",
    "    \"k\": \"j\",\n",
    "    \"l\": \"k\",\n",
    "    \"m\": \"l\",\n",
    "    \"n\": \"m\",\n",
    "    \"o\": \"n\",\n",
    "    \"p\": \"o\",\n",
    "    \"q\": \"p\",\n",
    "    \"r\": \"q\",\n",
    "    \"s\": \"r\",\n",
    "    \"t\": \"s\",\n",
    "    \"u\": \"t\",\n",
    "    \"v\": \"u\",\n",
    "    \"w\": \"v\",\n",
    "    \"x\": \"w\",\n",
    "    \"y\": \"x\",\n",
    "    \"z\": \"y\"  # Wrap-around mapping\n",
    "}\n",
    "# Apply reverse transformation to text before applying poisoning font\n",
    "reversed_font_map={val:key for key,val in font_map.items()}\n",
    "\n",
    "\n",
    "def create_font_poisoning_html(output_path_attak_method, title, body, id):\n",
    "    font_path_poisoned = os.path.join(pwd, 'PoisonedFont.ttf')\n",
    "    path = output_path_attak_method\n",
    "    font_poisoned = os.path.join(pwd, \"PoisonedFont.ttf\")\n",
    "    path_html = os.path.join(path, f\"{id}_default.html\")\n",
    "    title=title.lower()\n",
    "    body=body.lower()\n",
    "    create_html_with_font(path_html, title, body,font_path)\n",
    "    \n",
    "    map_letters_in_file(path_html, reversed_font_map, path_html)\n",
    "    modify_font(path_html, font_poisoned, path_html)\n",
    "\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    font_poisoning_path = os.path.join(dataset_obf, \"Font_poisoning\")\n",
    "    if not os.path.exists(font_poisoning_path):\n",
    "        os.makedirs(font_poisoning_path)\n",
    "    create_font_poisoning_html(font_poisoning_path, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Unicode Bidi override characters\n",
    "PDF = chr(0x202C)\n",
    "LRE = chr(0x202A)\n",
    "RLE = chr(0x202B)\n",
    "LRO = chr(0x202D)\n",
    "RLO = chr(0x202E)\n",
    "\n",
    "PDI = chr(0x2069)\n",
    "LRI = chr(0x2066)\n",
    "RLI = chr(0x2067)\n",
    "\n",
    "# Class to apply Unicode Bidi override characters to obfuscate text\n",
    "class Swap():\n",
    "    \"\"\"Represents swapped elements in a string of text.\"\"\"\n",
    "    def __init__(self, one, two):\n",
    "        self.one = one\n",
    "        self.two = two\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Swap({self.one}, {self.two})\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.one == other.one and self.two == other.two\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.one, self.two))\n",
    "\n",
    "def some(*els):\n",
    "    \"\"\"Returns the arguments as a tuple with Nones removed.\"\"\"\n",
    "    return tuple(filter(None, tuple(els)))\n",
    "\n",
    "def swaps(chars: str) -> set:\n",
    "    \"\"\"Generates all possible swaps for a string.\"\"\"\n",
    "    def pairs(chars, pre=(), suf=()):\n",
    "        orders = set()\n",
    "        for i in range(len(chars)-1):\n",
    "            prefix = pre + tuple(chars[:i])\n",
    "            suffix = suf + tuple(chars[i+2:])\n",
    "            swap = Swap(chars[i+1], chars[i])\n",
    "            pair = some(prefix, swap, suffix)\n",
    "            orders.add(pair)\n",
    "            orders.update(pairs(suffix, pre=some(prefix, swap)))\n",
    "            orders.update(pairs(some(prefix, swap), suf=suffix))\n",
    "        return orders\n",
    "    return pairs(chars) | {tuple(chars)}\n",
    "\n",
    "def unswap(el: tuple) -> str:\n",
    "    \"\"\"Reverts a tuple of swaps to the original string.\"\"\"\n",
    "    if isinstance(el, str):\n",
    "        return el\n",
    "    elif isinstance(el, Swap):\n",
    "        return unswap((el.two, el.one))\n",
    "    else:\n",
    "        res = \"\"\n",
    "        for e in el:\n",
    "            res += unswap(e)\n",
    "        return res\n",
    "\n",
    "def uniswap(els):\n",
    "    res = \"\"\n",
    "    for el in els:\n",
    "        if isinstance(el, Swap):\n",
    "            res += uniswap([LRO, LRI, RLO, LRI, el.one, PDI, LRI, el.two, PDI, PDF, PDI, PDF])\n",
    "        elif isinstance(el, str):\n",
    "            res += el\n",
    "        else:\n",
    "            for subel in el:\n",
    "                res += uniswap([subel])\n",
    "    return res\n",
    "\n",
    "def strings_to_file(file, string):\n",
    "  with open(file, 'w') as f:\n",
    "      for swap in swaps(string):\n",
    "          uni = uniswap(swap)\n",
    "          print(uni, file=f)\n",
    "\n",
    "def print_strings(string):\n",
    "  for swap in swaps(string):\n",
    "    uni = uniswap(swap)\n",
    "    print(uni)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_reordering_attack_html(output_path_attak_method, title, body, id):\n",
    "\n",
    "    target_word=select_target_word(body)\n",
    "    swapped_words =swaps(target_word)\n",
    "\n",
    "    obfuscated_words=[uniswap(swap) for swap in swapped_words]\n",
    "    #select random obfuscated word\n",
    "    obfuscated_word = obfuscated_words[np.random.randint(len(obfuscated_words))]\n",
    "\n",
    "    #manage reorder case where obfuscated word is == target word\n",
    "    while obfuscated_word == target_word:\n",
    "        print(f'Reorder attack: Got same words [{target_word},{obfuscated_word}] after reordering. Trying again...')\n",
    "        obfuscated_word = obfuscated_words[np.random.randint(len(obfuscated_words))]\n",
    "        \n",
    "    tag_list=['title','h1','p','li']\n",
    "    path_html = os.path.join(output_path_attak_method, f\"{id}_{target_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, title.replace(target_word,obfuscated_word), body.replace(target_word,obfuscated_word),font_path)\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    reorder_path = os.path.join(dataset_obf, \"Reordering_attacks\")\n",
    "    if not os.path.exists(reorder_path):\n",
    "        os.makedirs(reorder_path)\n",
    "    create_reordering_attack_html(reorder_path, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diactricial marks injection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def has_diacritical_accent(text):\n",
    "    diacritical_accents = \"àèéìòùÀÈÉÌÒÙ\"\n",
    "    return any(char in diacritical_accents for char in text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def obfuscate_diacritical(word, times = 10):\n",
    "    diacritical_accents = \"àèéìòùÀÈÉÌÒÙ\"\n",
    "    #chek witch diacritical accent is in the word\n",
    "\n",
    "    for i,char in enumerate(word):\n",
    "        if char in diacritical_accents:\n",
    "            if char in (\"à\", \"è\", \"ì\", \"ò\", \"ù\", \"À\", \"È\", \"É\", \"Ì\", \"Ò\", \"Ù\"):\n",
    "                word = word[:i+1] + '\\u0300'*times + word[i+1:]\n",
    "\n",
    "            else:\n",
    "                word = word[:i+1] + '\\u0301'*times + word[i+1:]\n",
    "    return word\n",
    "   \n",
    "    #replace the accent with the unicode character\n",
    "diacritical_accents = \"àèéìòùÀÈÉÌÒÙ\"\n",
    "\n",
    "def select_target_diacritical_word(text):\n",
    "    words = re.split(r'\\W+', text)  # Split by any non-word characters\n",
    "    words = [word for word in words if word.isalpha()]  # Keep only words with alphabetic characters\n",
    "    \n",
    "    if not words:\n",
    "        raise ValueError(\"No valid candidate words found.\")\n",
    "    \n",
    "    valid_words = [word for word in words if len(word) >= 2]  # Filter words by minimum length of 2 characters\n",
    "    \n",
    "    if not valid_words:\n",
    "        raise ValueError(\"No valid candidate words found with the required length.\")\n",
    "    \n",
    "    diacritical_words = [word for word in words if any(char in diacritical_accents for char in word)]\n",
    "    \n",
    "    if diacritical_words:\n",
    "        target_word = random.choice(diacritical_words)\n",
    "    else:\n",
    "        #rise an exception\n",
    "        raise ValueError(\"No valid candidate diacritial words found.\")\n",
    "    \n",
    "    return target_word\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_diactricial_marks_injection_mask1_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    #set the target word random form body\n",
    "    target_word=select_target_word(body)\n",
    "    #select random obfuscated word among word with accent\n",
    "    \n",
    "    target_word = select_target_diacritical_word(body)\n",
    "    obfuscated_word = obfuscate_diacritical(target_word)\n",
    "\n",
    "    \n",
    "\n",
    "    poisoned_title=title.replace(target_word,obfuscated_word)\n",
    "    poisoned_body=body.replace(target_word,obfuscated_word)\n",
    "    \n",
    "    path_html = os.path.join(path, f\"{id}_{target_word}.html\")\n",
    "    create_html_with_roboto(path_html, poisoned_title, poisoned_body)\n",
    "\n",
    "    return path_html\n",
    "\n",
    "def create_diactricial_marks_injection_mask2_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    #set the target word random form body\n",
    "    target_word=select_target_word(body)\n",
    "    #select random obfuscated word among word with accents\n",
    "        \n",
    "    target_word = select_target_diacritical_word(body)\n",
    "    obfuscated_word = obfuscate_diacritical(target_word, 4096**2*2)\n",
    "\n",
    "    \n",
    "\n",
    "    poisoned_title=title.replace(target_word,obfuscated_word)\n",
    "    poisoned_body=body.replace(target_word,obfuscated_word)\n",
    "    \n",
    "    path_html = os.path.join(path, f\"{id}_{target_word}.html\")\n",
    "    create_html_with_roboto(path_html, poisoned_title, poisoned_body)\n",
    "\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    diacritical_mask1_path = os.path.join(dataset_obf, \"Diactricial_marks_injection_mask1\")\n",
    "    if not os.path.exists(diacritical_mask1_path):\n",
    "        os.makedirs(diacritical_mask1_path)\n",
    "    diacritical_mask2_path = os.path.join(dataset_obf, \"Diactricial_marks_injection_mask2\")\n",
    "    if not os.path.exists(diacritical_mask2_path):\n",
    "        os.makedirs(diacritical_mask2_path)\n",
    "    title = \"i love drùgs\"\n",
    "    body = \"i love drùgs and cofè\"\n",
    "    create_diactricial_marks_injection_mask1_html(diacritical_mask1_path, title, body, 1)\n",
    "    create_diactricial_marks_injection_mask2_html(diacritical_mask2_path, title, body, 2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import base64\n",
    "\n",
    "def protect_html_from_ocr(html_content, background_path, output_path):\n",
    "    \"\"\"\n",
    "    Modify the given HTML to include a background image that makes OCR harder.\n",
    "    \n",
    "    Args:\n",
    "        html_content (str): The input HTML content.\n",
    "        background_path (str): Path to the background image file.\n",
    "\n",
    "    Returns:\n",
    "        BeautifulSoup: Modified HTML with OCR protection.\n",
    "    \"\"\"\n",
    "    # Load the background image and convert it to a base64 string\n",
    "    with open(background_path, \"rb\") as bg_file:\n",
    "        bg_base64 = base64.b64encode(bg_file.read()).decode(\"utf-8\")\n",
    "        bg_data_uri = f\"data:image/png;base64,{bg_base64}\"\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(open(html_content), \"html.parser\")\n",
    "    \n",
    "    # Inject CSS styles for OCR protection\n",
    "    style_tag = soup.new_tag(\"style\")\n",
    "    style_tag.string = f'''\n",
    "    body {{\n",
    "        background: url({bg_data_uri}) repeat;\n",
    "        background-blend-mode: lighten;\n",
    "        color: black;\n",
    "        text-shadow: 2px 2px 4px rgba(200, 200, 200, 0.9);\n",
    "        font-weight: bold;\n",
    "        position: relative;\n",
    "    }}\n",
    "    \n",
    "    h1, p {{\n",
    "        position: relative;\n",
    "        z-index: 10;\n",
    "    }}\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Add the style tag to the head\n",
    "    if soup.head:\n",
    "        soup.head.append(style_tag)\n",
    "    else:\n",
    "        head_tag = soup.new_tag(\"head\")\n",
    "        head_tag.append(style_tag)\n",
    "        soup.insert(0, head_tag)\n",
    "\n",
    "    save_html_to_file(str(soup), output_path)\n",
    "\n",
    "background_path = os.path.join(pwd, \"data/images/bgcaptcha.jpeg\")\n",
    "def create_ocr_poisoning_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    #set the target word random form body\n",
    "    path_html = os.path.join(output_path_attak_method, f\"{id}_default.html\")\n",
    "    create_html_with_font(path_html, title, body)\n",
    "    protect_html_from_ocr(path_html, background_path, path_html)\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    path_ocr_poisoning = os.path.join(dataset_obf, \"OCR-poisoning_injection\")\n",
    "    if not os.path.exists(path_ocr_poisoning):\n",
    "        os.makedirs(path_ocr_poisoning)\n",
    "    title = \"i love drugs\"\n",
    "    body = \"i love drugs\"\n",
    "    create_ocr_poisoning_html(path_ocr_poisoning, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Injection words\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "words_df=pd.read_csv('unigram_freq.csv')\n",
    "lowest_freq_words=words_df.sort_values('count',ascending=True).head(2000)['word'].tolist()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "words_current_index = 0\n",
    "\n",
    "def get_next_word():\n",
    "    global words_current_index\n",
    "    word = lowest_freq_words[words_current_index]\n",
    "    words_current_index = (words_current_index + 1) % len(lowest_freq_words)\n",
    "    return word\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Transparent"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_hidden_text_to_body_bg_color(html_content, tag_name, text_content, background_color, output_path):\n",
    "    \"\"\"\n",
    "    Add an element to the body with text styled to match the background color.\n",
    "\n",
    "    Parameters:\n",
    "        html_content (str): The HTML content as a string.\n",
    "        tag_name (str): The name of the tag to add (e.g., 'h1', 'p').\n",
    "        text_content (str): The text content of the new element.\n",
    "        background_color (str): The color of the background and text (e.g., '#ffffff').\n",
    "        output_path (str): Output path of the file to be saved.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified HTML content as a string.\n",
    "    \"\"\"\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    if soup.body is None:\n",
    "        raise ValueError(\"No <body> tag found in the HTML document.\")\n",
    "    \n",
    "    # Create the new tag\n",
    "    new_tag = soup.new_tag(tag_name)\n",
    "    new_tag.string = text_content\n",
    "    \n",
    "    # Set the inline style to match text and background color\n",
    "    new_tag['style'] = f\"color: {background_color}; background-color: {background_color};\"\n",
    "    \n",
    "    # Append the new tag to the body\n",
    "    soup.body.append(new_tag)\n",
    "\n",
    "    save_html_to_file(str(soup), output_path)\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_hidden_text_to_body_opacity(html_content, tag_name, text_content, opacity_level,output_path):\n",
    "    \"\"\"\n",
    "    Add an element to the body with text styled to match the background color.\n",
    "\n",
    "    Parameters:\n",
    "        html_content (str): The HTML content as a string.\n",
    "        tag_name (str): The name of the tag to add (e.g., 'h1', 'p').\n",
    "        text_content (str): The text content of the new element.\n",
    "        output_path (str): Output path of the file to be saved.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified HTML content as a string.\n",
    "    \"\"\"\n",
    "    # Parse the HTML\n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    if soup.body is None:\n",
    "        raise ValueError(\"No <body> tag found in the HTML document.\")\n",
    "    \n",
    "    # Create the new tag\n",
    "    new_tag = soup.new_tag(tag_name)\n",
    "    new_tag.string = text_content\n",
    "    \n",
    "    # Set the inline style to match text and background color\n",
    "    new_tag['style'] = f\"opacity: {opacity_level};\"\n",
    "    \n",
    "    # Append the new tag to the body\n",
    "    soup.body.append(new_tag)\n",
    "\n",
    "    save_html_to_file(str(soup), output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_transparent_bg_html(output_path_attak_method, title, body, id):\n",
    "    #set the target word random form body\n",
    "    background_color = \"transparent\"\n",
    "    tag_name=\"h1\"\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(output_path_attak_method, f\"{id}_{hidden_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, title, body)\n",
    "    add_hidden_text_to_body_bg_color(path_html, tag_name, hidden_word, background_color, path_html)\n",
    "    return path_html\n",
    "def create_transparent_opacity01_html(output_path_attak_method, title, body, id):\n",
    "    #set the target word random form body\n",
    "    opacity_level = 0.0001\n",
    "    tag_name=\"h1\"\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(output_path_attak_method, f\"{id}_{hidden_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, title, body)\n",
    "    add_hidden_text_to_body_opacity(path_html, tag_name, hidden_word, opacity_level, path_html)\n",
    "    return path_html\n",
    "\n",
    "def create_transparent_opacity00_html(output_path_attak_method, title, body, id):\n",
    "    #set the target word random form body\n",
    "    opacity_level = 0\n",
    "    tag_name=\"h1\"\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(output_path_attak_method, f\"{id}_{hidden_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, title, body)\n",
    "    add_hidden_text_to_body_opacity(path_html, tag_name, hidden_word, opacity_level, path_html)\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    path_transparent_text_bg = os.path.join(dataset_injection, \"Transparent_Text_injection_background\")\n",
    "    if not os.path.exists(path_transparent_text_bg):\n",
    "        os.makedirs(path_transparent_text_bg)\n",
    "    path_transparent_text_opacity = os.path.join(dataset_injection, \"Transparent_Text_injection_opacity\")\n",
    "    if not os.path.exists(path_transparent_text_opacity):\n",
    "        os.makedirs(path_transparent_text_opacity)\n",
    "\n",
    "    title = \"i love drugs\"\n",
    "    body = \"i love drugs\"\n",
    "    create_transparent_bg_html(path_transparent_text_bg, title, body, 1)\n",
    "    create_transparent_opacity00_html(path_transparent_text_opacity, title, body, 1)\n",
    "    create_transparent_opacity01_html(path_transparent_text_opacity, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Margin"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_random_out_of_bounds_position():\n",
    "    \"\"\"\n",
    "    Generate random out-of-bounds positions based on predefined zones.\n",
    "    Returns a dictionary containing the 'top' and 'left' CSS values.\n",
    "    \"\"\"\n",
    "    # Define the zones for out-of-bounds positions\n",
    "    zones = {\n",
    "        #\"top\": {\"top\": f\"{random.uniform(-2500, -2000)}px\", \"left\": f\"{random.uniform(0, 1000)}px\"},\n",
    "        #\"bottom\": {\"top\": f\"{random.uniform(2000, 2500)}px\", \"left\": f\"{random.uniform(0, 1000)}px\"},\n",
    "        \"left\": {\"top\": f\"{random.uniform(0, 1000)}px\", \"left\": f\"{random.uniform(-2500, -2000)}px\"},\n",
    "        \"top_left\": {\"top\": f\"{random.uniform(-2500, -2000)}px\", \"left\": f\"{random.uniform(-2500, -2000)}px\"},\n",
    "        #\"top_right\": {\"top\": f\"{random.uniform(-500, -200)}px\", \"left\": f\"{random.uniform(2000, 2500)}px\"},\n",
    "        #\"bottom_left\": {\"top\": f\"{random.uniform(2000,2500)}px\", \"left\": f\"{random.uniform(-2500, -2000)}px\"},\n",
    "        \"bottom_right\": {\"top\": f\"{random.uniform(2000, 2500)}px\", \"left\": f\"{random.uniform(-2000, -2500)}px\"},\n",
    "    }\n",
    "    \n",
    "    # Randomly choose a zone\n",
    "    random_zone = random.choice(list(zones.keys()))\n",
    "    return zones[random_zone]\n",
    "\n",
    "def add_out_of_bounds_text(html_content, tag_name, text_content, output_path, position=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Add an element with out-of-bounds text using CSS positioning.\n",
    "\n",
    "    Parameters:\n",
    "        html_content (str): The HTML content as a string.\n",
    "        tag_name (str): The name of the tag to add (e.g., 'h1', 'p').\n",
    "        text_content (str): The text to insert as out-of-bounds content.\n",
    "        output_path (str): Output path of the file to be saved.\n",
    "        position (str): The CSS position property (default is 'absolute').\n",
    "        top (str): The top position (default is '-100px' to move out of view).\n",
    "        left (str): The left position (default is '-100px' to move out of view).\n",
    "\n",
    "    Returns:\n",
    "        str: The modified HTML content.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    # Create the new tag (e.g., <div>, <p>, <h1>)\n",
    "    new_tag = soup.new_tag(tag_name)\n",
    "    new_tag.string = text_content\n",
    "    \n",
    "    # Generate a random out-of-bounds position\n",
    "    coordinates = get_random_out_of_bounds_position()\n",
    "    top = coordinates['top']\n",
    "    left = coordinates['left']\n",
    "\n",
    "    # Apply CSS to move the text out of bounds\n",
    "    new_tag['style'] = f\"position: {position}; top: {-2500}; left: {left};\"\n",
    "    \n",
    "    # Append the new tag to the body\n",
    "    soup.body.append(new_tag)\n",
    "    \n",
    "    # Save file \n",
    "    save_html_to_file(str(soup), output_path)\n",
    "\n",
    "\n",
    "def create_out_of_margin_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "    tag_name=\"p\"\n",
    "    position=\"absolute\"\n",
    "\n",
    "\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "\n",
    "    \n",
    "    add_out_of_bounds_text(path_html,tag_name, hidden_word, path_html, position)\n",
    "\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    path_out_of_margin = os.path.join(dataset_injection, \"Out_of_margin_injection\")\n",
    "    if not os.path.exists(path_out_of_margin):\n",
    "        os.makedirs(path_out_of_margin)\n",
    "    title = \"i love drugs\"\n",
    "    body = \"i love drugs\"\n",
    "    create_out_of_margin_html(path_out_of_margin, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Size"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def inject_zero_size_text_font(html_content, tag_name, text_content, font_size, visibility, output_path):\n",
    "    \"\"\"\n",
    "    Inject text into the body with zero font size to make it invisible to the user.\n",
    "    \n",
    "    Parameters:\n",
    "        html_content (str): The HTML content as a string.\n",
    "        tag_name (str): The name of the tag to add (e.g., 'h1', 'p').\n",
    "        text_content (str): The text to inject with zero size.\n",
    "        output_path (str): Output path of the file to be saved.\n",
    "        \n",
    "        \n",
    "    Returns:\n",
    "        str: The modified HTML content.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    # Create a new tag (e.g., <div>, <p>, <span>)\n",
    "    new_tag = soup.new_tag(tag_name)\n",
    "    new_tag.string = text_content\n",
    "    \n",
    "    # Apply CSS to set font-size to 0 (invisible)\n",
    "    new_tag['style'] = f\"font-size: {font_size}; visibility: {visibility};\"\n",
    "    \n",
    "    soup.body.append(new_tag)\n",
    "    \n",
    "    # Save file\n",
    "    save_html_to_file(str(soup), output_path)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def inject_scaled_text(html_content, tag_name, text_content, scale_factor, visibility, output_path):\n",
    "    \"\"\"\n",
    "    Inject text into the body with a CSS transform scale to make it visually hidden.\n",
    "    \n",
    "    Parameters:\n",
    "        html_content (str): The HTML content as a string.\n",
    "        tag_name (str): The name of the tag to add (e.g., 'h1', 'p').\n",
    "        text_content (str): The text to inject with scaling.\n",
    "        scale_factor (float): The scaling factor (e.g., 0.01 for near-invisible text).\n",
    "        visibility (str): The visibility CSS property value (e.g., 'hidden' or 'visible').\n",
    "        output_path (str): Output path of the file to be saved.\n",
    "        \n",
    "    Returns:\n",
    "        str: The modified HTML content.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    # Create a new tag (e.g., <div>, <p>, <span>)\n",
    "    new_tag = soup.new_tag(tag_name)\n",
    "    new_tag.string = text_content\n",
    "    \n",
    "    # Apply CSS transform scale to make text nearly invisible\n",
    "    new_tag['style'] = f\"transform: scale({scale_factor}); visibility: {visibility}; display: inline-block;\"\n",
    "    \n",
    "    soup.body.append(new_tag)\n",
    "    \n",
    "    # Save file\n",
    "    save_html_to_file(str(soup), output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "def create_zero_size_text_font00_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "    tag_name=\"div\"\n",
    "    font_size= \"0\"\n",
    "    visibility=\"visible\"\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "    inject_zero_size_text_font(path_html,tag_name, hidden_word, font_size,visibility, path_html)\n",
    "    return path_html\n",
    "\n",
    "\n",
    "def create_zero_size_text_font01_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "    tag_name=\"div\"\n",
    "    font_size= \"0.1px\"\n",
    "    visibility=\"visible\"\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "    inject_zero_size_text_font(path_html,tag_name, hidden_word, font_size,visibility, path_html)\n",
    "    return path_html\n",
    "\n",
    "def create_zero_size_scaled_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "    tag_name=\"h1\"\n",
    "    scale_factor=0.01\n",
    "    visibility=\"visible\"\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "\n",
    "    inject_scaled_text(path_html,tag_name, hidden_word, scale_factor,visibility, path_html)\n",
    "\n",
    "    return path_html\n",
    "\n",
    "def create_zero_size_text_visibilityHidden_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "    tag_name=\"h1\"\n",
    "    font_size= \"18\"\n",
    "    visibility=\"hidden\"\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "    inject_zero_size_text_font(path_html,tag_name, hidden_word, font_size,visibility, path_html)\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    path_zero_size_text_zerofont = os.path.join(dataset_injection, \"Zero-size_Text_injection_font0\")\n",
    "    if not os.path.exists(path_zero_size_text_zerofont):\n",
    "        os.makedirs(path_zero_size_text_zerofont)\n",
    "    path_zero_size_text_zerofont01 = os.path.join(dataset_injection, \"Zero-size_scaled\")\n",
    "    if not os.path.exists(path_zero_size_text_zerofont01):\n",
    "        os.makedirs(path_zero_size_text_zerofont01)\n",
    "    \n",
    "\n",
    "    create_zero_size_text_font00_html(path_zero_size_text_zerofont, title, body, 1)\n",
    "    create_zero_size_text_font01_html(path_zero_size_text_zerofont, title, body, 1)\n",
    "    create_zero_size_scaled_html(path_zero_size_text_zerofont01, title, body, 1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def inject_metadata(html_content, metadata, output_path):\n",
    "    \"\"\"\n",
    "    Injects metadata into the <head> section of an HTML document.\n",
    "    \n",
    "    Parameters:\n",
    "    - html_content (str): The HTML content as a file path.\n",
    "    - metadata (list of dict): A list of metadata dictionaries. Each dict should have 'name' or 'property', and 'content'.\n",
    "    - output_path (str): The file path to save the modified HTML.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Saves the modified HTML to the output path.\n",
    "    \"\"\"\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(open(html_content), 'html.parser')\n",
    "    \n",
    "    # Find or create the <head> section\n",
    "    head = soup.head\n",
    "    if not head:\n",
    "        head = soup.new_tag('head')\n",
    "        soup.html.insert(0, head)\n",
    "    \n",
    "    # Find the style tag if it exists\n",
    "    style_tag = head.find('style')\n",
    "    \n",
    "    # Create all meta tags first\n",
    "    meta_tags = []\n",
    "    for meta in metadata:\n",
    "        meta_tag = soup.new_tag('meta')\n",
    "        \n",
    "        # Set attributes in specific order\n",
    "        if 'name' in meta:\n",
    "            meta_tag.attrs['name'] = meta['name']\n",
    "        elif 'property' in meta:\n",
    "            meta_tag.attrs['property'] = meta['property']\n",
    "            \n",
    "        if 'content' in meta:\n",
    "            meta_tag.attrs['content'] = meta['content']\n",
    "            \n",
    "        meta_tags.append(meta_tag)\n",
    "    \n",
    "    # Insert meta tags in appropriate location\n",
    "    if style_tag:\n",
    "        # Insert before style tag\n",
    "        for meta_tag in meta_tags:\n",
    "            style_tag.insert_before(meta_tag)\n",
    "    else:\n",
    "        # If no style tag, append to head\n",
    "        for meta_tag in meta_tags:\n",
    "            head.append(meta_tag)\n",
    "    \n",
    "    save_html_to_file(str(soup), output_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_metadata_hidden_text_html(output_path_attak_method, title, body, id):\n",
    "    path = output_path_attak_method\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "    metadata_to_add = [\n",
    "        {\"name\": \"description\", \"content\": f\"{hidden_word}\"},\n",
    "        {\"property\": \"og:summary\", \"content\": f\"{hidden_word}\"}\n",
    "    ]\n",
    "\n",
    "    inject_metadata(path_html, metadata_to_add, path_html)\n",
    "\n",
    "\n",
    "    return path_html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    path_metadata_hidden_text = os.path.join(dataset_injection, \"Metadata_Hidden_Text_injection\")\n",
    "    if not os.path.exists(path_metadata_hidden_text):\n",
    "        os.makedirs(path_metadata_hidden_text)\n",
    "\n",
    "    create_metadata_hidden_text_html(path_metadata_hidden_text, title, body, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decive Element"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import random\n",
    "\n",
    "def inject_hidden_text_behind_image(path_html, tag_name, image_selector, hidden_text, output_path, path_image):\n",
    "    \"\"\"\n",
    "    Injects hidden text behind the specified image in the HTML content.\n",
    "\n",
    "    Parameters:\n",
    "    - path_html (str): The path to the HTML file.\n",
    "    - image_selector (str): The selector (e.g., id, class, or tag) for the target image.\n",
    "    - hidden_text (str): The text to inject behind the image.\n",
    "    - output_path (str): Output path of the file to be saved.\n",
    "    - path_image (str): Path to the image file to be used.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified HTML content.\n",
    "    \"\"\"\n",
    "    # Parse the HTML\n",
    "    with open(path_html, 'r') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "    \n",
    "    # Find the image element using the selector\n",
    "    image = soup.select_one(image_selector)\n",
    "    \n",
    "    # If the image is not found, create and insert it\n",
    "    if not image:\n",
    "        image = soup.new_tag('img', src=path_image, id=image_selector.strip('#'))\n",
    "        soup.body.append(image)\n",
    "    else:\n",
    "        # Update the image source to use the provided path_image\n",
    "        image['src'] = path_image\n",
    "    \n",
    "    # Create a hidden text element\n",
    "    hidden_text_element = soup.new_tag(\n",
    "        tag_name, \n",
    "        style=(\n",
    "            \"position: absolute; \"\n",
    "            \"z-index: -1; \"  # Ensures it's behind the image\n",
    "            \"width: 100%; \"  # Makes the text span the entire width of its parent\n",
    "            \"left: 0; \"      # Align to the left edge of the parent\n",
    "            \"transform: translateY(-50%); \"  # Center vertically relative to its position\n",
    "            \"text-align: center; \"  # Ensure the text is invisible\n",
    "        )\n",
    "    )\n",
    "    hidden_text_element.string = hidden_text\n",
    "    \n",
    "    # Insert the hidden text behind the image\n",
    "    image.insert_before(hidden_text_element)\n",
    "\n",
    "    # Save the modified HTML content to the output path\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.write(str(soup))\n",
    "\n",
    "# Example usage in create_decived_html function\n",
    "def create_decived_html(path, title, body, id):\n",
    "    hidden_word = get_next_word()\n",
    "    path_html = os.path.join(path, f\"{id}_{hidden_word}.html\")\n",
    "\n",
    "    tag_name = \"h2\"\n",
    "    image_selector = \"#target-image\"  # This should match the ID of the target image in your HTML\n",
    "\n",
    "    create_html_with_font(path_html, title, body, font_path)\n",
    "    image_path = os.path.join(pwd, \"data/images/logo.png\")\n",
    "    inject_hidden_text_behind_image(path_html, tag_name, image_selector, hidden_word, path_html, image_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if DEBUG:\n",
    "    path_text_under_image = os.path.join(dataset_injection, \"Decived_injection\")\n",
    "    if not os.path.exists(path_text_under_image):\n",
    "        os.makedirs(path_text_under_image)\n",
    "\n",
    "    create_decived_html(path_text_under_image, title, body, 1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#restart dataset iterator\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Grocery_and_Gourmet_Food\", streaming=True, trust_remote_code=True)\n",
    "dataset_iterator = iter(dataset[\"full\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "attack_methods_obfuscation = {\n",
    "    \"Zero-Width_mask1\": create_zew_mask1_html,\n",
    "    \"Zero-Width_mask2\": create_zew_mask2_html,\n",
    "    \"Homoglyph_default\": create_homoglyph_html,\n",
    "    \"Font-poisoning_default\": create_font_poisoning_html,\n",
    "    \"Reordering-attack_default\": create_reordering_attack_html,\n",
    "    \"Diacritical-injection_mask1\": create_diactricial_marks_injection_mask1_html,\n",
    "    #\"Diactricial marks injection-mask2\": create_diactricial_marks_injection_mask2_html, #DDOS\n",
    "    \"OCR-poisoning_default\": create_ocr_poisoning_html\n",
    "}\n",
    "\n",
    "attack_methods_injection = {\n",
    "    \"Transparent-Text-injection_background-color\": create_transparent_bg_html,\n",
    "    \"Transparent-Text-injection_opacity00\": create_transparent_opacity00_html,\n",
    "    \"Transparent-Text-injection_opacity01\": create_transparent_opacity00_html,\n",
    "    \"Out-of-bound-injection_default\": create_out_of_margin_html,\n",
    "    \"Zero-size-injection_font00\": create_zero_size_text_font00_html,\n",
    "    \"Zero-size-injection_font01\": create_zero_size_text_font01_html,\n",
    "    \"Zero-size-injection_scaling\": create_zero_size_scaled_html,\n",
    "    \"Zero-size-injection_visibilityHidden\": create_zero_size_text_visibilityHidden_html,\n",
    "    \"Deceived-element-injection_default\": create_decived_html,\n",
    "    \"Metadata-injection_default\": create_metadata_hidden_text_html\n",
    "}\n",
    "\n",
    "super_class_map = {\n",
    "    \"Data obfuscation\": attack_methods_obfuscation,\n",
    "    \"Poisoned text injection\": attack_methods_injection\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "RECREATE = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Ottieni il percorso corrente\n",
    "pwd = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Definisci il percorso della cartella dataset\n",
    "dataset_path = os.path.join(pwd, \"data\", \"dataset\", \"HTML\")\n",
    "print(dataset_path)\n",
    "if RECREATE:\n",
    "    # Crea la cartella se non esiste\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(dataset_path)\n",
    "    else:\n",
    "        # Elimina tutti i file e le directory nella cartella dataset\n",
    "        files = glob.glob(os.path.join(dataset_path, '*'))\n",
    "        for f in files:\n",
    "            if os.path.isfile(f):\n",
    "                os.remove(f)\n",
    "            elif os.path.isdir(f):\n",
    "                shutil.rmtree(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def extract_sanitized(dataset_iterator):\n",
    "    \n",
    "    data_element = next(dataset_iterator)\n",
    "    title = data_element[\"title\"]\n",
    "    text = data_element[\"text\"]\n",
    "    \n",
    "    if not re.search(r'\\w+', text, re.IGNORECASE):\n",
    "        raise ValueError(\"No valid candidate words found. No words in the body\")\n",
    "    return title, text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "num_files = 100\n",
    "count = 0\n",
    "#crete the folders folder_names if not existing\n",
    "for super_class in super_class_map:\n",
    "    if not os.path.exists(os.path.join(dataset_path, super_class)):\n",
    "        os.makedirs(os.path.join(dataset_path, super_class))\n",
    "    else :\n",
    "        print(\"folder already exists\")\n",
    "        # #remove all files in the folder\n",
    "        shutil.rmtree(os.path.join(dataset_path, super_class))\n",
    "        os.makedirs(os.path.join(dataset_path, super_class))\n",
    "    for sub_class in super_class_map[super_class]:\n",
    "        if not os.path.exists(os.path.join(dataset_path, super_class, sub_class)):\n",
    "            os.makedirs(os.path.join(dataset_path, super_class, sub_class))\n",
    "            print(os.path.join(dataset_path, super_class, sub_class))\n",
    "            path_pdf = os.path.join(dataset_path, super_class, sub_class)\n",
    "        \n",
    "        #ocr\n",
    "        if (sub_class ==  \"OCR-poisoning_default\") :\n",
    "            ocr_mapping_df_path=\"../ocr_mapping.csv\"\n",
    "            #if file does not exist, create new df\n",
    "            if not os.path.exists(ocr_mapping_df_path):\n",
    "                ocr_df=pd.DataFrame(columns=[\"file\", \"full_file_path\",\"title\",'text','joint_text'])\n",
    "                ocr_df.to_csv(ocr_mapping_df_path, index=False)\n",
    "            else:\n",
    "                ocr_df=pd.read_csv(ocr_mapping_df_path)\n",
    "    \n",
    "            for i in range(num_files):    \n",
    "                while True:  # Loop to retry if an error occurs\n",
    "                    try:\n",
    "\n",
    "                        title, text = extract_sanitized(dataset_iterator)\n",
    "\n",
    "                        joint_text = title + \"\\n\\n\" + text\n",
    "                        \n",
    "\n",
    "                        creation = super_class_map[super_class][sub_class]\n",
    "                        path_pdf_file=creation(path_pdf, title, text, i)\n",
    "                        print(path_pdf_file)\n",
    "\n",
    "                        file_name=os.path.basename(path_pdf_file)\n",
    "\n",
    "                        ocr_df.loc[len(ocr_df)] = {\n",
    "                            \"file\": file_name,\n",
    "                            \"full_file_path\": path_pdf_file,\n",
    "                            \"title\": title,\n",
    "                            \"text\": text,\n",
    "                            \"joint_text\": joint_text\n",
    "                        }\n",
    "                        break  # Exit the loop if successful\n",
    "                    except StopIteration:\n",
    "                        print(\"No more elements in the dataset.\")\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error occurred: {e}. Retrying with the next dataset element..., cout error {count}\")\n",
    "                        print(path_pdf)\n",
    "                        print (title)\n",
    "                        print (text)\n",
    "                        count += 1\n",
    "                        continue  # Retry with the next dataset element\n",
    "            ocr_df.to_csv(ocr_mapping_df_path, index=False)\n",
    "\n",
    "        elif (sub_class=='Font-poisoning_default'):\n",
    "            font_poisoning_mapping_df_path=\"../font_poisoning_mapping.csv\"\n",
    "            #if file does not exist, create new df\n",
    "            if not os.path.exists(font_poisoning_mapping_df_path):\n",
    "                font_poisoning_df=pd.DataFrame(columns=[\"file\",\"full_file_path\", \"title\",'text','joint_text'])\n",
    "                font_poisoning_df.to_csv(font_poisoning_mapping_df_path, index=False)\n",
    "            else:\n",
    "                font_poisoning_df=pd.read_csv(font_poisoning_mapping_df_path)\n",
    "    \n",
    "            for i in range(num_files):    \n",
    "                while True:  # Loop to retry if an error occurs\n",
    "                    try:\n",
    "                        title, text = extract_sanitized(dataset_iterator)\n",
    "\n",
    "\n",
    "                        joint_text = title + \"\\n\\n\" + text\n",
    "                        \n",
    "                        creation = super_class_map[super_class][sub_class]\n",
    "                        path_pdf_file=creation(path_pdf, title, text, i)\n",
    "                        print(path_pdf_file)\n",
    "\n",
    "                        file_name=os.path.basename(path_pdf_file)\n",
    "                        font_poisoning_df.loc[len(font_poisoning_df)] = {\n",
    "                            \"file\": file_name,\n",
    "                            \"full_file_path\": path_pdf_file,\n",
    "                            \"title\": title,\n",
    "                            \"text\": text,\n",
    "                            \"joint_text\": joint_text\n",
    "                        }\n",
    "\n",
    "                        break  # Exit the loop if successful\n",
    "                    except StopIteration:\n",
    "                        print(\"No more elements in the dataset.\")\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error occurred: {e}. Retrying with the next dataset element..., cout error {count}\")\n",
    "                        print(path_pdf)\n",
    "                        print (title)\n",
    "                        print (text)\n",
    "                        count += 1\n",
    "                        continue  # Retry with the next dataset element\n",
    "            font_poisoning_df.to_csv(font_poisoning_mapping_df_path,index=False)\n",
    "        \n",
    "        elif (sub_class ==  \"Diacritical-injection_mask1\" or sub_class ==  \"Diacritical-injection_mask2\") :\n",
    "            for i in range(num_files):    \n",
    "                \n",
    "                # Iterate until a title with a diacritical accent is found\n",
    "                found = False\n",
    "                while not found:\n",
    "                    try:\n",
    "                        title, text = extract_sanitized(dataset_iterator)\n",
    "\n",
    "                        \n",
    "                        if has_diacritical_accent(title):                       \n",
    "                            # Create the PDF\n",
    "                            print(path_pdf)\n",
    "                            creation = super_class_map[super_class][sub_class]\n",
    "                            print(creation(path_pdf, title, text, i))\n",
    "                            found = True\n",
    "                            \n",
    "                    except StopIteration:\n",
    "                        print(\"No more elements in the dataset.\")\n",
    "                        break  # Exit the loop if no more elements are available\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error occurred: {e}. Retrying with the next dataset element...\")\n",
    "                        continue  # Retry with the next element if an error occurs\n",
    "\n",
    "    \n",
    "        else :\n",
    "            for i in range(num_files):    \n",
    "                while True:  # Loop to retry if an error occurs\n",
    "                    try:\n",
    "                        title, text = extract_sanitized(dataset_iterator)\n",
    "                        \n",
    "                        creation = super_class_map[super_class][sub_class]\n",
    "                        print(creation(path_pdf, title, text, i))\n",
    "                        break  # Exit the loop if successful\n",
    "                    except StopIteration:\n",
    "                        print(\"No more elements in the dataset.\")\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error occurred: {e}. Retrying with the next dataset element..., cout error {count}\")\n",
    "                        #print(path_pdf)\n",
    "                        #print (title)\n",
    "                        #print (text)\n",
    "                        count += 1\n",
    "                        continue  # Retry with the next dataset element\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
